{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import bkw2d_implicit_score_matching as ism\n",
    "import bkw2d_sampling as sp\n",
    "import bkw2d_particle as par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current time:  0\n",
      "Iter 1000, L2 Loss: 3.70767e-02, ISM Loss: -3.82933e+00\n",
      "Iter 2000, L2 Loss: 7.67073e-03, ISM Loss: -3.96921e+00\n",
      "Iter 3000, L2 Loss: 3.15272e-03, ISM Loss: -4.01268e+00\n",
      "Iter 4000, L2 Loss: 1.73147e-03, ISM Loss: -4.05760e+00\n",
      "Iter 5000, L2 Loss: 1.12379e-03, ISM Loss: -4.09866e+00\n",
      "Iter 6000, L2 Loss: 7.89858e-04, ISM Loss: -4.10384e+00\n",
      "Iter 7000, L2 Loss: 5.72771e-04, ISM Loss: -4.09454e+00\n",
      "Iter 7420, Loss: 4.99596e-04, ISM Loss: -4.09454e+00\n",
      "33.346088699999996\n",
      "current time:  0.01\n",
      "Iter 5, ISM Loss: -4.06090e+00, L2 Loss: 1.66420e-03\n",
      "Iter 10, ISM Loss: -4.06640e+00, L2 Loss: 1.84519e-03\n",
      "Iter 15, ISM Loss: -4.07050e+00, L2 Loss: 2.30012e-03\n",
      "Iter 20, ISM Loss: -4.07429e+00, L2 Loss: 2.70620e-03\n",
      "Iter 25, ISM Loss: -4.07782e+00, L2 Loss: 2.78732e-03\n",
      "0.4244922000000031\n",
      "current time:  0.02\n",
      "Iter 5, ISM Loss: -4.04264e+00, L2 Loss: 3.71154e-03\n",
      "Iter 10, ISM Loss: -4.04662e+00, L2 Loss: 3.73052e-03\n",
      "Iter 15, ISM Loss: -4.05014e+00, L2 Loss: 3.88195e-03\n",
      "Iter 20, ISM Loss: -4.05344e+00, L2 Loss: 4.12903e-03\n",
      "Iter 25, ISM Loss: -4.05660e+00, L2 Loss: 4.18616e-03\n",
      "0.44152579999999375\n",
      "current time:  0.03\n",
      "Iter 5, ISM Loss: -4.01923e+00, L2 Loss: 5.25649e-03\n",
      "Iter 10, ISM Loss: -4.02252e+00, L2 Loss: 5.35793e-03\n",
      "Iter 15, ISM Loss: -4.02534e+00, L2 Loss: 5.37180e-03\n",
      "Iter 20, ISM Loss: -4.02805e+00, L2 Loss: 5.46444e-03\n",
      "Iter 25, ISM Loss: -4.03058e+00, L2 Loss: 5.61281e-03\n",
      "0.3498495000000048\n",
      "current time:  0.04\n",
      "Iter 5, ISM Loss: -3.99247e+00, L2 Loss: 6.72452e-03\n",
      "Iter 10, ISM Loss: -3.99551e+00, L2 Loss: 6.78166e-03\n",
      "Iter 15, ISM Loss: -3.99807e+00, L2 Loss: 6.73188e-03\n",
      "Iter 20, ISM Loss: -4.00054e+00, L2 Loss: 6.93519e-03\n",
      "Iter 25, ISM Loss: -4.00290e+00, L2 Loss: 7.01840e-03\n",
      "0.3861441999999897\n",
      "current time:  0.05\n",
      "Iter 5, ISM Loss: -3.96342e+00, L2 Loss: 8.37156e-03\n",
      "Iter 10, ISM Loss: -3.96657e+00, L2 Loss: 8.56121e-03\n",
      "Iter 15, ISM Loss: -3.96907e+00, L2 Loss: 8.17272e-03\n",
      "Iter 20, ISM Loss: -3.97099e+00, L2 Loss: 8.25947e-03\n",
      "Iter 25, ISM Loss: -3.97301e+00, L2 Loss: 8.47534e-03\n",
      "0.2961591000000112\n",
      "current time:  0.060000000000000005\n",
      "Iter 5, ISM Loss: -3.93314e+00, L2 Loss: 1.03269e-02\n",
      "Iter 10, ISM Loss: -3.93624e+00, L2 Loss: 9.56006e-03\n",
      "Iter 15, ISM Loss: -3.93794e+00, L2 Loss: 9.57818e-03\n",
      "Iter 20, ISM Loss: -3.93984e+00, L2 Loss: 9.74944e-03\n",
      "Iter 25, ISM Loss: -3.94185e+00, L2 Loss: 9.60708e-03\n",
      "0.3818582000000106\n",
      "current time:  0.07\n",
      "Iter 5, ISM Loss: -3.90187e+00, L2 Loss: 1.12449e-02\n",
      "Iter 10, ISM Loss: -3.90491e+00, L2 Loss: 1.12164e-02\n",
      "Iter 15, ISM Loss: -3.90671e+00, L2 Loss: 1.09394e-02\n",
      "Iter 20, ISM Loss: -3.90838e+00, L2 Loss: 1.08449e-02\n",
      "Iter 25, ISM Loss: -3.91034e+00, L2 Loss: 1.09765e-02\n",
      "0.36866649999998913\n",
      "current time:  0.08\n",
      "Iter 5, ISM Loss: -3.87037e+00, L2 Loss: 1.30736e-02\n",
      "Iter 10, ISM Loss: -3.87329e+00, L2 Loss: 1.22247e-02\n",
      "Iter 15, ISM Loss: -3.87478e+00, L2 Loss: 1.21832e-02\n",
      "Iter 20, ISM Loss: -3.87649e+00, L2 Loss: 1.23267e-02\n",
      "Iter 25, ISM Loss: -3.87833e+00, L2 Loss: 1.21302e-02\n",
      "0.3092433999999855\n",
      "current time:  0.09\n",
      "Iter 5, ISM Loss: -3.83844e+00, L2 Loss: 1.39108e-02\n",
      "Iter 10, ISM Loss: -3.84133e+00, L2 Loss: 1.38060e-02\n",
      "Iter 15, ISM Loss: -3.84295e+00, L2 Loss: 1.35097e-02\n",
      "Iter 20, ISM Loss: -3.84446e+00, L2 Loss: 1.33517e-02\n",
      "Iter 25, ISM Loss: -3.84626e+00, L2 Loss: 1.34163e-02\n",
      "0.4911277999999868\n",
      "current time:  0.09999999999999999\n",
      "Iter 5, ISM Loss: -3.80650e+00, L2 Loss: 1.56518e-02\n",
      "Iter 10, ISM Loss: -3.80928e+00, L2 Loss: 1.47182e-02\n",
      "Iter 15, ISM Loss: -3.81062e+00, L2 Loss: 1.46469e-02\n",
      "Iter 20, ISM Loss: -3.81221e+00, L2 Loss: 1.47497e-02\n",
      "Iter 25, ISM Loss: -3.81390e+00, L2 Loss: 1.44937e-02\n",
      "0.3715063000000214\n",
      "current time:  0.10999999999999999\n",
      "Iter 5, ISM Loss: -3.77431e+00, L2 Loss: 1.63267e-02\n",
      "Iter 10, ISM Loss: -3.77709e+00, L2 Loss: 1.61646e-02\n",
      "Iter 15, ISM Loss: -3.77857e+00, L2 Loss: 1.58633e-02\n",
      "Iter 20, ISM Loss: -3.77998e+00, L2 Loss: 1.56427e-02\n",
      "Iter 25, ISM Loss: -3.78164e+00, L2 Loss: 1.56450e-02\n",
      "0.44520829999999023\n",
      "current time:  0.11999999999999998\n",
      "Iter 5, ISM Loss: -3.74233e+00, L2 Loss: 1.79337e-02\n",
      "Iter 10, ISM Loss: -3.74502e+00, L2 Loss: 1.69403e-02\n",
      "Iter 15, ISM Loss: -3.74627e+00, L2 Loss: 1.68351e-02\n",
      "Iter 20, ISM Loss: -3.74775e+00, L2 Loss: 1.68939e-02\n",
      "Iter 25, ISM Loss: -3.74934e+00, L2 Loss: 1.65863e-02\n",
      "0.29843210000001363\n",
      "current time:  0.12999999999999998\n",
      "Iter 5, ISM Loss: -3.71032e+00, L2 Loss: 1.83988e-02\n",
      "Iter 10, ISM Loss: -3.71302e+00, L2 Loss: 1.81733e-02\n",
      "Iter 15, ISM Loss: -3.71438e+00, L2 Loss: 1.78679e-02\n",
      "Iter 20, ISM Loss: -3.71571e+00, L2 Loss: 1.76002e-02\n",
      "Iter 25, ISM Loss: -3.71728e+00, L2 Loss: 1.75447e-02\n",
      "0.3870428999999831\n",
      "current time:  0.13999999999999999\n",
      "Iter 5, ISM Loss: -3.67871e+00, L2 Loss: 1.98057e-02\n",
      "Iter 10, ISM Loss: -3.68133e+00, L2 Loss: 1.87513e-02\n",
      "Iter 15, ISM Loss: -3.68250e+00, L2 Loss: 1.86120e-02\n",
      "Iter 20, ISM Loss: -3.68389e+00, L2 Loss: 1.86368e-02\n",
      "Iter 25, ISM Loss: -3.68541e+00, L2 Loss: 1.82851e-02\n",
      "0.3197170999999912\n",
      "current time:  0.15\n",
      "Iter 5, ISM Loss: -3.64732e+00, L2 Loss: 2.00444e-02\n",
      "Iter 10, ISM Loss: -3.64995e+00, L2 Loss: 1.97469e-02\n",
      "Iter 15, ISM Loss: -3.65116e+00, L2 Loss: 1.94341e-02\n",
      "Iter 20, ISM Loss: -3.65246e+00, L2 Loss: 1.91102e-02\n",
      "Iter 25, ISM Loss: -3.65395e+00, L2 Loss: 1.90001e-02\n",
      "0.41724080000000185\n",
      "current time:  0.16\n",
      "Iter 5, ISM Loss: -3.61654e+00, L2 Loss: 2.12059e-02\n",
      "Iter 10, ISM Loss: -3.61911e+00, L2 Loss: 2.00866e-02\n",
      "Iter 15, ISM Loss: -3.62021e+00, L2 Loss: 1.99228e-02\n",
      "Iter 20, ISM Loss: -3.62153e+00, L2 Loss: 1.99253e-02\n",
      "Iter 25, ISM Loss: -3.62299e+00, L2 Loss: 1.95286e-02\n",
      "0.5392340000000218\n",
      "current time:  0.17\n",
      "Iter 5, ISM Loss: -3.58627e+00, L2 Loss: 2.11914e-02\n",
      "Iter 10, ISM Loss: -3.58881e+00, L2 Loss: 2.08481e-02\n",
      "Iter 15, ISM Loss: -3.58991e+00, L2 Loss: 2.05542e-02\n",
      "Iter 20, ISM Loss: -3.59118e+00, L2 Loss: 2.02014e-02\n",
      "Iter 25, ISM Loss: -3.59260e+00, L2 Loss: 2.00445e-02\n",
      "0.3861415000000079\n",
      "current time:  0.18000000000000002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m     start\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m---> 30\u001b[0m     fisher_divergence\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_ism\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     31\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(end\u001b[38;5;241m-\u001b[39mstart)\n",
      "File \u001b[1;32mc:\\Users\\hyhy0\\Documents\\科研\\Landau\\Score-based Landau\\implict_score_landau\\BKW 2d\\bkw2d_implicit_score_matching.py:86\u001b[0m, in \u001b[0;36mScoreMatching.train_ism\u001b[1;34m(self, max_iter)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_ism\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     85\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mism_loss(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples)\n\u001b[1;32m---> 86\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_ism\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     88\u001b[0m ism_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pytorch_cuda117\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pytorch_cuda117\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "T = 5 # terminal time\n",
    "t = 0 # initial time\n",
    "dt = 0.01 # time step\n",
    "Nt = int((T-t)/dt) # steps\n",
    "\n",
    "energy=[]\n",
    "entropy_decay_rate=[]\n",
    "fisher_divergence=[]\n",
    "particle_traj=[]\n",
    "\n",
    "'''initial sampling'''\n",
    "nex=100**2\n",
    "sampling_model = sp.Sampling(nex=nex, time=t, seed=23)\n",
    "v = np.array(sampling_model.rejection_sampling())\n",
    "particle_traj.append(v)\n",
    "#f_net = par.f_exact(v, t)\n",
    "\n",
    "'''evolution'''\n",
    "for nt in range(Nt):\n",
    "    \n",
    "    print('current time: ', t)\n",
    "    model = ism.ScoreMatching(samples=v, time=t)\n",
    "    if nt==0:\n",
    "        start=time.perf_counter()\n",
    "        fisher_divergence.append(model.train_L2(tol=5e-4))\n",
    "        end = time.perf_counter()\n",
    "        print(end-start)\n",
    "    else:\n",
    "        start=time.perf_counter()\n",
    "        fisher_divergence.append(model.train_ism(max_iter=25))\n",
    "        end = time.perf_counter()\n",
    "        print(end-start)\n",
    "    model.save_model()\n",
    "\n",
    "    # compute score at t_{n}\n",
    "    score = model.compute_score(v)\n",
    "    # compute velocity field\n",
    "    velocity_field = par.compute_velocity_field(v, score)\n",
    "    # compute entropy, energy\n",
    "    entropy_decay_rate.append(par.compute_entropy_decay_rate(velocity_field, score))\n",
    "    energy.append(par.compute_energy(v))\n",
    "    # compute density at t_{n+1}\n",
    "    # score_jac = model.compute_score_jac(v)\n",
    "    # logdet_field = par.compute_logdet_field(v, score, score_jac)\n",
    "    # f_net = par.compute_f(f_net, logdet_field, dt)\n",
    "    # compute v at t_{n+1}\n",
    "    v = par.compute_v(v, velocity_field, dt)\n",
    "    particle_traj.append(v)\n",
    "    t += dt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cuda117",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
